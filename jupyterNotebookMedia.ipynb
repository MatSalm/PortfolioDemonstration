{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 guide to working Free AWS PySpark instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello, the purpose of this notebook is to help every aspiring data scientist, data analyst, data engineer, and even individuals in who are just curious how to brush up on Spark when they have a low-powered machine with very limited resources in the year 2020. \n",
    "\n",
    "In this example we will be setting up pySpark using EC2 instances and remaining in the \"free tier\" in AWS. You an use this cluster to write code using a small sample of data then apply to the full dataset, use it to follow along with a class, or learn another intersting way to spin up Spark clusters other than EMR, DataBricks, or local instances to be used if you only have a tablet or chromebook handy.\n",
    "\n",
    "The security setting we will choose are rather low, but you can start and stop your server as you see fit and this way you can login from anywhere in the world and start your coding. No more excuses about not being able to study because you have no access to powerful machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first thing you need to do is setup an AWS account, but this will still make you enter inyour credit card, but do not worry as everything we will be doing falls within the AWS free tier. I will not cover how to setup an AWS account, but I will provide this helpful link. You will also need a valid email address.\n",
    "\n",
    "    https://aws.amazon.com/free\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin setting up your free pySpark cluster in AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is our plan:\n",
    "   * Create EC2 instance on ASW\n",
    "   * Use SSH (Secure Shell COnnetion) to connect to ECR over internet (Windows) with a nice bonus\n",
    "   * Set-up Spark and Jupyter on EC2 Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use Windows instead of Mac or Linux becasue SSH with those is only 2 simple command lines, but Windows has enough steps to make it complicated for new users without help the first time.\n",
    "\n",
    "We will start with the consol which is what you will see once you log into AWS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we will select ECR and begin launching an instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to EC2 from the consol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step1](https://github.com/MatSalm/PortfolioDemonstration/blob/master/1_navigateToEC2.gif?raw=true \"step1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we will seect \"Ubuntu Server 18.04 LTS (HVM), SSD Volume Type\" and make sure it says \"Free tier elegible\"\n",
    "\n",
    "We will select the \"General Purpose\" instance \"t2.micro\" which is the smallest instance offering 1 core and 1GB memory. The best part of the free tier is you get 720-750 free hours per month of free tier EC2 instances, but none in EMR which is why we are using EC2 instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step2](https://github.com/MatSalm/PortfolioDemonstration/blob/master/2_selectYourInstances.gif?raw=true \"step2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configring our instance to remain in the free tier means we will only select QTY 1 node. The purpose of this instance is to work with small datasets for practise. If you need more compute I suggest you use EMR, but this will take you out of free tier.\n",
    "\n",
    "You will get 8GB of storage in this instance free as an EBS volume (storage dedicated to your instance like a hard drive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step3](https://github.com/MatSalm/PortfolioDemonstration/blob/master/3_numNodesAndStorage.gif?raw=true \"step3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we will add our tags and configure a security group:\n",
    "\n",
    "•\tHere the key is '\"myspark\" and the value is \"mymachine\" and you should make note of this for later.\n",
    "\n",
    "#### Next you want to make sure \"Crete new security group\" is selected and change the type to \"All Traffic\"\n",
    "\n",
    "•\tYou will see a security warning here, but you want to easily access your EC2 instance. If you are on a company platform or need additional security you will want to add additional security to your instance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step4](https://github.com/MatSalm/PortfolioDemonstration/blob/master/4_tagsAndSecurity.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select \"Launch\" in the lower right corner and you need to select your key pair which will allow you access to your EC2 instance. It is **VERY IMPORTANT** to select \"Download Key Pair\" which will give you a .pem file. Do not lose this file or you will need to start all over again. You cannot get a new key pair for this instance. Select \"Launch instance.\"\n",
    "\n",
    "Proceed to the next step as your instance is launching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step5](https://github.com/MatSalm/PortfolioDemonstration/blob/master/5_keyPairDownload.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up PUTTY on Windows to SSH into your EC2 Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigate to the link below for full PUTTY documentation. I will be performing these steps below. \n",
    "\n",
    "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/putty.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is the link you will need to access the downloads:\n",
    "\n",
    "https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html\n",
    "\n",
    "We will install 2 programs from this page. These are links to the 64-bit versions so if you need the 32-bit versions then select the link above and choose those files.\n",
    "\n",
    "* putty.exe\n",
    "https://the.earth.li/~sgtatham/putty/latest/w64/putty.exe\n",
    "\n",
    "* puttygen.exe\n",
    "https://the.earth.li/~sgtatham/putty/latest/w64/puttygen.exe\n",
    "\n",
    "Move these files to your desktop along with the .pem file as we will use them shortly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/6_navigateToPUTTY.gif?raw=true\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some information about our instance which we will gather over the next few steps.\n",
    "\n",
    "We need:\n",
    "* ID of our instance\n",
    "* Public DNS name\n",
    "* Our private key (remember the .pem file we downlaoded)\n",
    "\n",
    "We also need to enable SSH, but we did this when we selected \"all inbound traffic,\" but you could have just opened port 22 after launching your instance. For the sake of simplicity and practise we kept it simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covert the .pem file into .ppk with puttygen.exe for windows to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you open puttygen.exe the .pem file will not readily show, so select \"all files\" in your windows explorer. Remember I put all of the files I need onto my desktop for ease of presentation (putty.exe, puttygen.exe, and newspark.pem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/7_getPPK.gif?raw=true\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are now going to start a putty session using that .ppk file we just created as our private key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need our DNS name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/8_DNSname.gif?raw=true\" width=\"700\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need our instance ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/9_isntanceID..gif?raw=true\" width=\"700\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add our .ppk file to putty. \n",
    "\n",
    "Open putty.exe, under the navigation pane (it says \"Category:\") select **Connection -> SSH -> Auth**\n",
    "\n",
    "under \"**Private key file for authentication:**\" select browse and find your .ppk file we just made. It is located on my desktop as this is where I had the .pem file.\n",
    "\n",
    "We will also be entering the Information from our EC2 Instance\n",
    "* Be sure to type \"ubuntu@\" then paste your DNS name into putty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/10_SSHin(1)..gif?raw=true\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now SSH'ed into your Ubuntu server in AWS. \n",
    "\n",
    "The server that pops up is ready to use. If you typed \"python3\" then \"print('Hello')\" you can execute this. You can then type \"quit()\" to exit python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/11_pythonExample.gif?raw=true\" width=\"700\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations on EC2 Ubuntu Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As cool as it is to already have python running, the goal here is to have Spark running in a Jupyter Notebook. Saprk has the capability to use multithreading, near infiinite cumpute, memory, and storage capacity (as long as you have more nodes to give it), and can query your data using SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this portion of the excersise we will:\n",
    "\n",
    "* Install Spark on EC2\n",
    "* Install Jupyter Notebook on EC2\n",
    "* Open our notebook through the browser using port 8888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the following commands on your server in this order, one at a time\n",
    "\n",
    "##### Update our server OS\n",
    "\n",
    "    sudo apt-get update\n",
    "\n",
    "#####  Install pip (hit y for \"yes\" when prompted)\n",
    "\n",
    "    sudo apt install python3-pip\n",
    "\n",
    "##### Install Jupyter Notebook \n",
    "\n",
    "    sudo apt install jupyter-notebook \n",
    "\n",
    "##### Install Java, incase it is not already installed (hit y for \"yes\" when prompted)\n",
    "(know that spark is written in scala, which is written in java, so making sure you have java is essential)\n",
    "\n",
    "    sudo apt-get install default-jre\n",
    "\n",
    "##### Install Scala (hit y for \"yes\" when prompted)\n",
    "\n",
    "    sudo apt-get install scala\n",
    "\n",
    "##### Install py4J library\n",
    "    \n",
    "    pip3 install py4j\n",
    "\n",
    "##### Install Spark\n",
    "\n",
    "    wget http://archive.apache.org/dist/spark/spark-2.1.1/spark-2.1.1-bin-hadoop2.7.tgz\n",
    "\n",
    "##### Unzip the .tgz file\n",
    "    \n",
    "    sudo tar -zxvf spark-2.1.1-bin-hadoop2.7.tgz\n",
    "    \n",
    "##### cd into the spark folder \n",
    "\n",
    "    cd spark-2.1.1-bin-hadoop2.7/\n",
    "\n",
    "##### type \"pwd\" and remember your \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7\" file path\n",
    "\n",
    "    pwd\n",
    "\n",
    "##### cd back to your home directory\n",
    "\n",
    "    cd\n",
    "\n",
    "##### Install findspark module to help connect python with spark\n",
    "\n",
    "    pip3 install findspark\n",
    "    \n",
    " \n",
    "    \n",
    "##### make .pem files we will use for our Jupyter configuration file\n",
    "\n",
    "    jupyter notebook --generate-config\n",
    "    \n",
    "    mkdir certs\n",
    "    \n",
    "    cd certs\n",
    "    \n",
    "    sudo openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout mycert.pem -out mycert.pem\n",
    "    \n",
    "**(You will hit a part where the server is asking you for information. You can fill this out or you can keep hitting enter and leave it blank until you reach your command line again. I personally do not mind filling in my location data.)**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Edit the configuration file you made \n",
    "\n",
    "    cd ~/.jupyter/\n",
    "\n",
    "    vi jupyter_notebook_config.py\n",
    "    \n",
    "#### Here is where it gets tricky. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have open your jupyter notebook configuration file. We need to edit the configuration file. Follow these instructions carefully.\n",
    "\n",
    "1) press \"i\" on your keyboard\n",
    "\n",
    "2) Arrow to under the first line \"# Configuration file for jupyter notebook\" and add these lines into the config file. The open_browser=False command will prevent the notebook from opening in the browser by default on start.\n",
    "\n",
    "* c = get_config()\n",
    "* c.NotebookApp.certfile = u'/home/ubuntu/certs/mycert.pem'\n",
    "* c.NotebookApp.ip = '*'\n",
    "* c.NotebookApp.open_browser = False\n",
    "* c.NotebookApp.port = 8888\n",
    "\n",
    "3) press \"ESC\" on your keybaord\n",
    "\n",
    "4) type \":wq!\"\n",
    "\n",
    "5) hit \"Enter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/12_configFile.gif?raw=true\" width=\"700\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Step before starting Jupyter Notebook\n",
    "\n",
    "In order to connect to your instance with \"EC2 Instance Connect (browser-based SSH connection)\" you need to install ec2-instance-connect to your AMI.\n",
    "\n",
    "    sudo apt-get install ec2-instance-connect \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type the code below to return to your home directory and start your process of loggin into your personal server\n",
    "  \n",
    "    cd \n",
    "\n",
    "    jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output message will say \"Copy/paste this URL into your browser when you conenct for hte first time.\" the token which was generated for me is below. (since we are using putty, but highlight the token and it will save to your clipboard. If you do ctrl+c then it will ask of you want to terminate the server, so do not do this). Also, your token will change every time so I inluded an easier way to access your token to login below.\n",
    "\n",
    "#### We need to make changes to this link by adding the DNS address \n",
    "Remember we already used our DNS address when logging in with putty, so you should have this available or know where it is at.\n",
    "\n",
    "replace \"localhost\" in the url provided with your DNS name and paste into your browser\n",
    "\n",
    "**my token before**\n",
    "https://localhost:8888/?token=21182a8fe774db44c7dfba73c56597d9fea9827fe0e90b76\n",
    "\n",
    "**my token after**\n",
    "https://ec2-100-26-199-27.compute-1.amazonaws.com:8888/?token=21182a8fe774db44c7dfba73c56597d9fea9827fe0e90b76\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/13_copytoken.gif?raw=true\" width=\"700\"/>\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will get an error because your browser is condering if the instance is trying to steal your inforamtion, which we know it is not. Proceed anyway. There will be an option on your screen under \"advanced.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/14_pasteURL.gif?raw=true\" width=\"700\"/>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Jupyter Notebook to use PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember installing \"findspark\"? Now we will need this and the directory you saved from earlier.\n",
    "\n",
    "#### Run the following Code in your jupyter notebook\n",
    "\n",
    "    import findspark\n",
    "    \n",
    "    findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "    \n",
    "    import pyspark\n",
    "    \n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    spark = SparkSession.builder.appName('FromMattsTutorial').getOrCreate()\n",
    "    \n",
    "    spark.version  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now able to type and use PySpark on your own personal EC2 instance. You can upload datasets using the directory which intially pops up when we opened a new notebook session. You will want to save these lines of code as you will always need to start a new spark session each time anyway, but feel free to use this FREE server anytime to practise python3 OR pyspark OR just make a cool markdown for your side interests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/15_StartSparkSession.gif?raw=true\" width=\"700\"/>\n",
    "</div> \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close down you Jupyter Notebook since we were liberal with our permissions\n",
    "\n",
    "You could just open port 8888 and 22 to be more secure. there are enough free hours where you can leave this running 29 days out of the month with guaranteed $0 charges. you can also limit permissions via roles using IAM, but that is outside the scope of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/17_ShutDown.gif?raw=true\" width=\"700\"/>\n",
    "</div> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another easier way to get access your token \n",
    "\n",
    "Here we use the direct connect feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://github.com/MatSalm/PortfolioDemonstration/blob/master/16_connectButton.gif?raw=true\" width=\"700\"/>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For those who do not mind paying a little extra (about $5 per 24 hours of runtime) for a basic 4-core , 32GB, Pyspark Multithreaded Experience in 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Click the link below**\n",
    "\n",
    "You shuold terminate this EMR cluster after each use. It is super easy to access, super easy to spin up, and you can connect to an existing S3 bucket where your keep you datasets.\n",
    "\n",
    "I will be opening port 8890 and 22, but they will need to be closed before spinning up your next cluster and re-opened to prevent your cluster from self terminating (unless you configure a security group). \n",
    "\n",
    "This is a full video with great quality and limited explanation. It is that easy.\n",
    "\n",
    "Please notice I type \":8890\" after the DNS name to begin using the zeppelin notebook\n",
    "\n",
    "You will need to execute this code at the begining of each session and include \"%pyspark\" which will automatically appear in each code chunk from now on.\n",
    "    \n",
    "    %pyspark\n",
    "    \n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    spark = SparkSession.builder.appName('mySessionName').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Click here for the 2020 Tutorial to Create AWS EMR PySpark Cluster](https://youtu.be/RVReQHo7LEM/0.jpg)](https://www.youtube.com/watch?v=RVReQHo7LEM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
